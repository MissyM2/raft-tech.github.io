<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Neural Networks</title>
  <meta name="description" content="CIO LEVEL SUMMARY:  Neural Networks (NNs) are a useful and flexible tool that can helplearn patterns from data that humans cannot">
  
  <meta name="author" content="Ben Centra">
  <meta name="copyright" content="&copy; Ben Centra 2020">
  

  <!-- External libraries -->
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/styles/monokai-sublime.min.css">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/lightbox2/2.7.1/css/lightbox.css">

  <!-- Favicon and other icons (made with http://www.favicon-generator.org/) -->
  <link rel="shortcut icon" href="http://healthstarinfo.com/goraft./assets/icons/favicon.ico" type="image/x-icon">
  <link rel="icon" href="http://healthstarinfo.com/goraft./assets/icons/favicon.ico" type="image/x-icon">
  <link rel="apple-touch-icon" sizes="57x57" href="http://healthstarinfo.com/goraft./assets/icons/apple-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="http://healthstarinfo.com/goraft./assets/icons/apple-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="http://healthstarinfo.com/goraft./assets/icons/apple-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="http://healthstarinfo.com/goraft./assets/icons/apple-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="http://healthstarinfo.com/goraft./assets/icons/apple-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="http://healthstarinfo.com/goraft./assets/icons/apple-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="http://healthstarinfo.com/goraft./assets/icons/apple-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="http://healthstarinfo.com/goraft./assets/icons/apple-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="http://healthstarinfo.com/goraft./assets/icons/apple-icon-180x180.png">
  <link rel="icon" type="image/png" sizes="192x192"  href="http://healthstarinfo.com/goraft./assets/icons/android-icon-192x192.png">
  <link rel="icon" type="image/png" sizes="32x32" href="http://healthstarinfo.com/goraft./assets/icons/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="96x96" href="http://healthstarinfo.com/goraft./assets/icons/favicon-96x96.png">
  <link rel="icon" type="image/png" sizes="16x16" href="http://healthstarinfo.com/goraft./assets/icons/favicon-16x16.png">
  <link rel="manifest" href="http://healthstarinfo.com/goraft./assets/icons/manifest.json">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="msapplication-TileImage" content="http://healthstarinfo.com/goraft./assets/icons/ms-icon-144x144.png">
  <meta name="theme-color" content="#ffffff">

  
  <!-- Facebook OGP cards -->
  <meta property="og:description" content="CIO LEVEL SUMMARY:  Neural Networks (NNs) are a useful and flexible tool that can helplearn patterns from data that humans cannot" />
  <meta property="og:url" content="http://localhost:4000/2018/10/12/a-gentle-intorduction-to-feed-forward-neural-networks.html">
  <meta property="og:site_name" content="Raft" />
  <meta property="og:title" content="Neural Networks" />
  <meta property="og:type" content="website" />
  <meta property="og:image" content="http://localhost:4000http://healthstarinfo.com/goraft/assets/logo.png" />
  <meta property="og:image:type" content="image/png" />
  <meta property="og:image:width" content="612" />
  <meta property="og:image:height" content="605" />
  

  
  <!-- Twitter: card tags -->
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Neural Networks">
  <meta name="twitter:description" content="CIO LEVEL SUMMARY:  Neural Networks (NNs) are a useful and flexible tool that can helplearn patterns from data that humans cannot">
  <meta name="twitter:image" content="http://localhost:4000http://healthstarinfo.com/goraft/assets/logo.png">
  <meta name="twitter:url" content="http://localhost:4000/2018/10/12/a-gentle-intorduction-to-feed-forward-neural-networks.html">
  

  

  <!-- Site styles -->
  <link rel="stylesheet" href="http://healthstarinfo.com/goraft/css/main.css">
  <link rel="canonical" href="http://localhost:4000http://healthstarinfo.com/goraft/2018/10/12/a-gentle-intorduction-to-feed-forward-neural-networks.html">
	<link rel="alternate" type="application/rss+xml" title="Raft" href="http://localhost:4000http://healthstarinfo.com/goraft/feed.xml" />

	<!-- Tooltips -->
	<script type="text/javascript">
		window.tooltips = []
	</script>
</head>


  <body>

    <header class="navigation" role="banner">
  <div class="navigation-wrapper">
    <a href="http://healthstarinfo.com/goraft/" class="logo">
      
      <div class="left">
        <img src="http://healthstarinfo.com/goraft/assets/logo.png" alt="Raft">
      </div>
      
    </a>
    <a href="javascript:void(0)" class="navigation-menu-button" id="js-mobile-menu">
      <i class="fa fa-bars"></i>
    </a>
    <nav role="navigation">
      <ul id="js-navigation-menu" class="navigation-menu show">
				<li class="nav-link"><a href="/">Home</a>


	

	

	

	

	

	

	

	

	
	<li class="nav-link"><a href="http://healthstarinfo.com/goraft/about/">About</a>
	

	
	<li class="nav-link"><a href="http://healthstarinfo.com/goraft/services/">Services</a>
	

	

	
	<li class="nav-link"><a href="http://healthstarinfo.com/goraft/contact/">Contact</a>
	

	
	<li class="nav-link"><a href="http://healthstarinfo.com/goraft/blog/">Blog</a>
	


      </ul>
    </nav>
  </div>
</header>


    <div class="page-content">
        <div class="home post">

<div class="post-header-container " >
  <div class="scrim ">
    <header class="post-header">
      <h1 class="title">Neural Networks</h1>
      <div class="post-date">
        October 12, 2018
      </div>
      <section class="share_header">
  
    
    
      <a href="//twitter.com/share?text=Neural+Networks&url=http%3A%2F%2Flocalhost%3A4000http%3A%2F%2Fhealthstarinfo.com%2Fgoraft%2F2018%2F10%2F12%2Fa-gentle-intorduction-to-feed-forward-neural-networks.html&via=TheBenCentra"
        onclick="window.open(this.href, 'twitter-share', 'width=550,height=255');return false;">
        <i class="fa fa-twitter fa-lg"></i>
      </a>
    
    
    
    
    
    
    
  
    
    
    
      <a href="//www.facebook.com/sharer.php?t=Neural+Networks&u=http%3A%2F%2Flocalhost%3A4000http%3A%2F%2Fhealthstarinfo.com%2Fgoraft%2F2018%2F10%2F12%2Fa-gentle-intorduction-to-feed-forward-neural-networks.html"
        onclick="window.open(this.href, 'facebook-share', 'width=550,height=255');return false;">
        <i class="fa fa-facebook fa-lg"></i>
      </a>
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
      <a href="//www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Flocalhost%3A4000http%3A%2F%2Fhealthstarinfo.com%2Fgoraft%2F2018%2F10%2F12%2Fa-gentle-intorduction-to-feed-forward-neural-networks.html"
        onclick="window.open(this.href, 'linkedin-share', 'width=550,height=255');return false;">
        <i class="fa fa-linkedin fa-lg"></i>
      </a>
    
    
    
    
  
    
    
    
    
      <a href="//plus.google.com/share?title=Neural+Networks&url=http%3A%2F%2Flocalhost%3A4000http%3A%2F%2Fhealthstarinfo.com%2Fgoraft%2F2018%2F10%2F12%2Fa-gentle-intorduction-to-feed-forward-neural-networks.html"
        onclick="window.open(this.href, 'google-plus-share', 'width=550,height=255');return false;">
        <i class="fa fa-google-plus fa-lg"></i>
      </a>
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
      <a href="//www.pinterest.com/pin/create/button/?description=Neural+Networks&url=http%3A%2F%2Flocalhost%3A4000http%3A%2F%2Fhealthstarinfo.com%2Fgoraft%2F2018%2F10%2F12%2Fa-gentle-intorduction-to-feed-forward-neural-networks.html&media=http://localhost:4000http://healthstarinfo.com/goraft/assets/header_image.jpg"
        onclick="window.open(this.href, 'pinterest-share', 'width=550,height=255');return false;">
        <i class="fa fa-pinterest fa-lg"></i>
      </a>
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
      <a href="//www.reddit.com/submit" onclick="window.location = '//www.reddit.com/submit?url=' + encodeURIComponent('http://localhost:4000http://healthstarinfo.com/goraft/2018/10/12/a-gentle-intorduction-to-feed-forward-neural-networks.html') + '&title=Neural Networks'; return false">
        <i class="fa fa-reddit fa-lg"></i>
      </a>
    
    
  
    
    
    
    
    
    
    
    
  
</section>


    </header>
  </div>
</div>

<div class="wrapper">



<section class="post-meta">
  <div class="post-categories">
  
  </div>
</section>

<article class="post-content">
  <p><strong>CIO LEVEL SUMMARY:</strong></p>
<ul>
  <li>
    <p>Neural Networks (NNs) are a useful and flexible tool that can help
learn patterns from data that humans cannot</p>
  </li>
  <li>
    <p>Neural Networks contain layers of nodes which feed directly into the
following layer. As information moves through the NN, information is
weighted and combined</p>
  </li>
  <li>
    <p>Once a prediction is made, the Neural Network compares its
predictions to the desired output</p>
  </li>
  <li>
    <p>Neural Networks learn by figuring out how to tweak its calculations
in order to reduce the amount of errors it makes</p>
  </li>
</ul>

<p><strong>WHAT ARE NEURAL NETS?</strong></p>

<p>Neural Networks have gotten a lot of attention in the past few decades.
They’re used in social media apps like Snapchat, and they’re being used
more and more in the medical and health fields<sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup>.</p>

<p>Neural Networks--or Neural Nets for short--are an incredibly flexible
tool to have in your analytical tool belt because they are <strong>universal
approximators</strong><sup id="fnref:2"><a href="#fn:2" class="footnote">2</a></sup><strong>.</strong> This means that under certain assumptions, a
neural network can approximate any function.</p>

<p>Imagine that you’re building a toy helicopter. You grab some supplies
like plastic, wood, and glue, and you get started. The first thing you
need to do is make the propellor out of plastic. But you’re not sure how
to do it...if you were an expert, you might know how to cut and shape
the propeller by hand. But you’re not an expert. So you’re stuck.</p>

<p>Someone hands you a box, and tells you that it’s a universal tool
approximator. All you have to do is show it a few examples of the
propellers that you want, input some plastic, and it will learn how to
output the propellers. The box learns the process that takes raw plastic
and turns it into a propeller...or at least it gets close enough.</p>

<p><img src="//healthstarinfo.com/blogs/assets/images/intro_to_nn_pics/Picture1.png" alt="" class="center-image" /></p>

<p>The *best* thing about this box is that it can learn to make or do
*anything*. When you need cap for your pen, or a buckle for your belt,
a box can learn how to make it.</p>

<p>Neural Networks are similar to these boxes. But their inputs and outputs
are numbers, rather than materials and gadgets.</p>

<p>Often, we want Neural Networks to approximate the relationship between
data (the input) and some kind of prediction (our output). For example,
we may want to approximate the relationship between features from a
digitized image of a fine needle aspirate of a breast mass<sup id="fnref:3"><a href="#fn:3" class="footnote">3</a></sup> and
whether or not it’s malignant. We can use the variables radius, texture,
perimeter, area, smoothness, and symmetry of the tumor cell nuclei as
our inputs.</p>

<p><img src="//healthstarinfo.com/blogs/assets/images/intro_to_nn_pics/Picture2.png" alt="" class="center-image" /></p>

<p>We can call the true relationship that maps the inputs (radius, texture,
perimeter, area, smoothness, and symmetry) onto the output (malignancy
diagnosis)  <script type="math/tex">f^*(x)</script> .</p>

<p><img src="//healthstarinfo.com/blogs/assets/images/intro_to_nn_pics/Picture3.png" alt="" class="center-image" /></p>

<p>The Neural Network learns what <script type="math/tex">f^*(x)</script> is from the data. It won’t always get
<script type="math/tex">f^*(x)</script> perfectly correct, but it can come up with some function
<script type="math/tex">f(x)</script> that is close. This is a huge help, because often the function that
turns inputs into outputs is complex, and would be hard for a human to
discover on their own.</p>

<p><strong>THE STRUCTURE</strong></p>

<p>Neural Networks use layers of <strong>nodes</strong> to take data from inputs to
outputs.</p>

<p>For now, let’s think of each node as something that stores a value. The
first layer is our input layer. It’s nodes represent the data that we
feed into our network.</p>

<p><img src="//healthstarinfo.com/blogs/assets/images/intro_to_nn_pics/Picture4.png" alt="" class="center-image" /></p>

<p>The last layer is the output layer, which has two nodes, one for
Malignant. One for Benign. Each of these nodes will eventually have a
value in them once we turn our inputs into outputs. Whichever node has a
higher value, will be the diagnosis we choose.</p>

<p>So now, let’s focus on the middle layers, called <strong>hidden layers.</strong></p>

<p><strong>THE HIDDEN LAYERS</strong></p>

<p>Let’s add one layer between our input and output layer.</p>

<p><img src="//healthstarinfo.com/blogs/assets/images/intro_to_nn_pics/Picture5.png" alt="" class="center-image" /></p>

<p>This first hidden layer contains four nodes, and we need to fill these
nodes with values. These values are calculated using the values from the
layer before them. Let’s focus on just one of these nodes for now. The
values from the input layer are weighted and added together to form a
single number. In general the weight
<script type="math/tex">w^l_{(i,j)}%0</script>
connects the <script type="math/tex">i^th</script> node from the <script type="math/tex">l^th</script> layer to the <script type="math/tex">j^th</script> neuron of the
<script type="math/tex">l+1^th</script> layer.</p>

<p><img src="//healthstarinfo.com/blogs/assets/images/intro_to_nn_pics/Picture6.png" alt="" class="center-image" /></p>

<p>We also add a constant--called the bias--to this equation. In this
form, it might look similar to a linear regression formula.</p>

<script type="math/tex; mode=display">w^1_{(1,1)}R + w^1_{(2,1)}T + w^1_{(3,1)}P + w^1_{(4,1)}A + w^1_{(5,1)}Sm +w^1_{(6,1)}Sy + b = \textbf{w'}x \\ \text{where x is a vector of data, [R,T,P,A,Sm,Sy]}</script>

<p>The final step is to apply an <strong>activation function</strong> to the result
<script type="math/tex">(w'x)</script> of this equation. The activation function takes the weighted inputs and
bias, and transforms it. If we wanted the value to remain unchanged, we
could apply the function <script type="math/tex">f(x) = x</script>. But, there are many different
activation functions we can use.</p>

<p>One popular one is the <strong>Rectified Linear Unit</strong>, or ReLU (pronounced
Rey-Loo) for short. The ReLU activation function takes all negative
numbers, and turns them into zeroes. It leaves positive numbers
unchanged. Non-linear activation functions like the ReLU are an
important part of what allows Neural Networks to approximate nonlinear
functions. Without them, Neural Nets would only be able to approximate
linear functions.</p>

<p>Once we’ve added up all the weighted inputs and the bias, and applied an
activation function, we finally have a value to put into our node.</p>

<script type="math/tex; mode=display">h = max\{0,\textbf{w'}x\}%0</script>

<p><img src="//healthstarinfo.com/blogs/assets/images/intro_to_nn_pics/Picture7.png" alt="" class="center-image" /></p>

<p>And then, we fill in the rest of the nodes for this layer, doing the
same thing, but with different weights and biases.</p>

<p>And then we use the values in the second layer to compute the values in
the third and fourth layers.</p>

<p>The general steps are:</p>

<ol>
  <li>
    <p>Add the weighted values from the previous layer together</p>
  </li>
  <li>
    <p>Add the bias</p>
  </li>
  <li>
    <p>Apply the activation function</p>
  </li>
</ol>

<p><img src="//healthstarinfo.com/blogs/assets/images/intro_to_nn_pics/Picture8.png" alt="" class="center-image" /></p>

<p>We can use different activation functions for each layer. In fact for
the last layer, we’ll want to use a <strong>softmax</strong> activation. Softmax is
often used when the outputs you’d like to predict are categorical. It
takes all the values from that layer and normalizes them so that they’re
all between 0 and 1, and the sum of all the outputs is 1.</p>

<script type="math/tex; mode=display">\text{Softmax:} \frac{e^{z_i}}{\Sigma^{k}_{i = 1}e^{z_i}}%0</script>

<p>After applying the softmax activation, we can use these new outputs as
probabilities, or as a measure of how strongly the Network believes a
value is the correct answer.</p>

<p>For example, say that the values of our output layer are 1.6 and 4
before we apply the softmax activation.</p>

<p><img src="//healthstarinfo.com/blogs/assets/images/intro_to_nn_pics/Picture9.png" alt="" class="center-image" /></p>

<p>After applying the activation function, our values will be 0.08 and 0.92
since</p>

<script type="math/tex; mode=display">\frac{e^{1.6}}{e^{1.6} + e^{4}} \approx 0.08 \text{  and  } \frac{e^{4}}{e^{1.6} + e^{4}} \approx 0.92%0</script>

<p>In this case, the neural network will guess that the tumor is Benign,
since it has the higher value.</p>

<p><strong>THE MODEL</strong></p>

<p>So now we’ve built a Feed Forward Neural Network. We started with an
input layer which took in our data on breast tumors, and by moving
through two hidden layers, produced an output layer that can predict
whether a tumor is Malignant, or Benign.</p>

<p>From start to finish, we’ve been continually moving information forward,
from one layer directly to the next until we reach our output layer.
Hence, Feed Forward. This architecture is relatively simple, and yet it
has been used to do incredible things. Like help self driving cars make
decisions, and compress files<sup id="fnref:4"><a href="#fn:4" class="footnote">4</a></sup>.</p>

<p>The strength of the Neural Network is its ability to learn the weights,
biases, and sometimes the activation functions<sup id="fnref:5"><a href="#fn:5" class="footnote">5</a></sup>, necessary to
approximate the relationship between your inputs and outputs.</p>

<p><strong>Error Functions</strong></p>

<p>Before we give the Neural Network any data, we randomly initialize the
weights and biases, just so that it has some numbers to start with. Then
we give it some data--the training data--and look at it’s outputs. At
first, the outputs will be garbage, since our weights were randomly
initialized and don’t mean anything. But the Neural Net, like mature
humans, learns from its mistakes.</p>

<p><img src="//healthstarinfo.com/blogs/assets/images/intro_to_nn_pics/Picture10.png" alt="" class="center-image" /></p>

<p>We can compare the output the neural net gave us to the output that we
want.</p>

<p>For example, if the neural network gave use the output from before, we’d
end up with a 0.08 for Malignant and 0.92 for Benign:</p>

<p><img src="//healthstarinfo.com/blogs/assets/images/intro_to_nn_pics/Picture11.png" alt="" class="center-image" /></p>

<p>We know that this particular tumor was Malignant, so our Neural Network
was pretty far off. The correct output would be a 1 for Malignant and 0
for Benign. Which would represent the Network being sure that the tumor
is Malignant.</p>

<p>We need a way to quantify just how wrong our prediction was. One common
way is the <strong>mean squared error</strong>.</p>

<script type="math/tex; mode=display">MSE =E((y - \hat{y})^2)%0</script>

<script type="math/tex; mode=display">MSE = \frac{1}{n}\Sigma_{i=1}^o(y_i - \hat{y_i})^2%0</script>

<p>The mean squared error is calculated by taking the difference between
your desired outcomes, and your predicted outcomes, and squaring them,
and adding them together.</p>

<script type="math/tex; mode=display">(1-0.08)^2 = 0.8464%0</script>

<script type="math/tex; mode=display">(0-0.92)^2 = 0.8464%0</script>

<p>There are other ways of measuring the error (also called the loss or
cost), and whichever function you use is called the <strong>error function</strong>
(also called the loss function or cost function).</p>

<p>We want to be as accurate as possible, so we want to <em>minimize</em> our
error function. And our error function is just a result of all the
processes, including the weights, biases, and activation functions that
we used in our neural network.</p>

<p>In order to minimize our error function, we need to change these
weights, biases, and activation functions so that our prediction is
closer to our desired output. But figuring out which tweaks to make to
these parameters isn’t immediately clear.</p>

<p>Imagine you’re a ball on this line. You want to find the lowest point.</p>

<p><img src="//healthstarinfo.com/blogs/assets/images/intro_to_nn_pics/Picture12.png" alt="" /></p>

<p><strong>Backpropagation</strong></p>

<p>If you were a particularly math inclined ball, you could take the
derivative and second derivatives of the function, and find the global
minimum. But that’s not always possible or cost effective. Instead, we
find the gradient of the error function.</p>

<p>The <strong>gradient</strong> is the rate of change of our error function.</p>

<p>It tells us how fast the error function changes when we make small
changes to our model parameters (like the weights, and biases). In other
words, if you fiddled with the weights and biases of the neural network,
how much would the Neural Network’s output change?</p>

<p>We often find the gradient using a method called <strong>backpropagation</strong>, or
backprop for short.</p>

<p>Backpropagation is a way of applying the chain rule from calculus to
calculate the gradient of our error function. The error function relies
on the output that our Neural Network produces. And that output depends
on the activation function we used. And the value we plugged into our
activation function depends on the weights and biases that we used.</p>

<p><img src="//healthstarinfo.com/blogs/assets/images/intro_to_nn_pics/Picture13.png" alt="" /></p>

<p>Backpropagation allows us to find our gradient (the derivative of the
error function with respect to our parameters) by looking at how small
changes in our weight and bias parameters change our weighted sum, <em>z</em>.
And then, how small changes in our weighted sum, <em>z</em>, affect the output
of our Neural Network, <em>a</em>. And finally, how small changes in our
output, <em>a</em>, affect the value of the error function, <em>J</em>.</p>

<script type="math/tex; mode=display">\underbrace{w = weights}_{\text{our weights}}%0</script>

<script type="math/tex; mode=display">\underbrace{z = \textbf{w'}x}_{\text{weighted sum of previous nodes}}%0</script>

<script type="math/tex; mode=display">\underbrace{a = \sigma(\textbf{w'}x)}_{\text{output after applying activation function to z}}%0</script>

<script type="math/tex; mode=display">\underbrace{J = (y - \bar{y})^2}_{\text{the error function}}%0</script>

<script type="math/tex; mode=display">\underbrace{\frac{\delta J}{\delta w}}_{\text{the gradient of our error function}} = \frac{\delta z}{\delta w}\frac{\delta a }{\delta z}\frac{\delta J}{\delta a}%0</script>

<p><strong>Gradient Descent</strong></p>

<p>So instead of doing a large calculation to find the absolute global
minimum, we can just take one step at a time towards a minimum. At each
step, we’ll look for the direction that is the steepest downhill, and
step there.</p>

<p><img src="//healthstarinfo.com/blogs/assets/images/intro_to_nn_pics/Picture14.png" alt="" /></p>

<p>One step at a time, we’ll reach a minimum.</p>

<p><img src="//healthstarinfo.com/blogs/assets/images/intro_to_nn_pics/Picture15.png" alt="" /></p>

<p>It may not be the *global* minimum. But it will be *a* minimum, and
usually that is good enough to help the Neural Network make accurate
predictions. This iterative algorithm for finding the minimum of a
function is called <strong>gradient descent</strong>, since we are descending the
gradient, and it’s often used to minimize the error function.</p>

<p>Practically, it can be computationally expensive to calculate the
gradient using <em>all</em> the training data. We’re often going to give the
Neural Net Thousands if not millions of data points, so calculating the
error for every one of those points could take a while. To make things
more efficient, we can use <strong>Stochastic Gradient Descent.</strong> Instead of
calculating the gradient using <em>all</em> of our training data, we use
smaller <em>samples</em> of our training data, to help speed up the
calculations.</p>

<p>We do sacrifice a little bit of accuracy by not using <em>all</em> the data
samples, but Stochastic Gradient Descent is often very effective at
finding an appropriate minimum. Even though it only uses smaller samples
of the data for each step.</p>

<p><strong>CONCLUSION</strong></p>

<p>So, we’ve found our gradient using backpropagation, and chosen which
direction to go using gradient descent or stochastic gradient descent,
we repeat the process again and again until we reach a place where our
error function is minimized. Hopefully, that means that our Neural
Network is making less errors than it was before. It’s learned
something!</p>

<p>We now have a Neural Network that’s pretty good at predicting whether a
breast tumor is Malignant, or Benign. If a new biopsy comes in, we can
feed our Neural Network the data, and ask for predictions. While the
expertise of doctors and specialists is still necessary, Neural Networks
like this one can help screen or triage cases so that doctors have more
time to spend with patients, and can direct their energy towards the
less clear cut cases.</p>

<p>If you can give a Neural Network enough data to learn from, their
performances are incredibly accurate.</p>

<p><strong>PYTHON</strong></p>

<p>Let’s train our own Neural Network in python using the Wisconsin Breast
Cancer Data Set<sup id="fnref:6"><a href="#fn:6" class="footnote">6</a></sup>.</p>

<p>We’ll use the package Keras to build our Neural Network in python.
First, let’s import all the functions we’ll need to run the code.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span><span class="n">KFold</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.optimizers</span> <span class="kn">import</span> <span class="n">SGD</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span>
</code></pre></div></div>

<p>Then, let’s read in our data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"data.csv"</span><span class="p">,</span> <span class="n">sep</span> <span class="o">=</span> <span class="s">","</span><span class="p">)</span>
</code></pre></div></div>
<p>Next, we’ll split our dataset into two parts, the data we’ll use to
train the Neural Network, and the data we’ll use to evaluate the Network
once it’s been trained. We’ll also z-score our features so that they’re
standardized.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="p">)[</span><span class="mi">1</span><span class="p">:]],</span><span class="n">data</span><span class="p">[</span><span class="s">"diagnosis"</span><span class="p">],</span>
 <span class="n">test_size</span><span class="o">=</span><span class="mf">0.20</span><span class="p">)</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_sc</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
<span class="n">X_test_sc</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
</code></pre></div></div>

<p>We’ll create a list that stores the number of nodes that are in each
layer of our network, so that we can reference it later.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">layer_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span> <span class="c1">#input, hidden1, hidden2,output
</span></code></pre></div></div>

<p>Our first layer has 6 nodes, since we have 6 features (radius, texture,
perimeter, area, smoothness, and symmetry). Our output layer has 2
nodes; one for Malignant and one for Benign. The two layers in the
middle have 4 and 3 nodes respectively.</p>

<p>Now, let’s tell python how we’d like to structure our model. We’ll give
it information about the number of layers, and their sizes, as well as
which activation functions we’d like to use.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span>
        <span class="n">input_dim</span><span class="o">=</span><span class="n">layer_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">units</span><span class="o">=</span><span class="n">layer_sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">activation</span><span class="o">=</span><span class="s">"relu"</span>
    <span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="n">layer_sizes</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
        <span class="n">activation</span><span class="o">=</span><span class="s">"relu"</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="n">layer_sizes</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span>
                    <span class="n">kernel_initializer</span><span class="o">=</span><span class="s">'uniform'</span><span class="p">,</span>
                    <span class="n">activation</span><span class="o">=</span><span class="s">"softmax"</span><span class="p">))</span>

<span class="n">sgd</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">decay</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">.9</span><span class="p">)</span>  <span class="c1"># Stochastic gradient descent
</span>
<span class="n">model</span><span class="o">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'mean_squared_error'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">sgd</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">"accuracy"</span><span class="p">])</span>

</code></pre></div></div>

<p>Then, we can train our model.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y_train_vectorized</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span> <span class="c1">#change Malignant/Benign to Categorical
</span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_sc</span><span class="p">,</span> <span class="n">y_train_vectorized</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>
<p>So now we have a Neural Network that has learned how to tell if biopsies
from breast tumors are Malignant of Benign. But we want to estimate how
accurate it is. If it can only give the correct diagnosis 50% of the
time, we may not want to deploy it.</p>

<p>To check the accuracy, we can run this code.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#grab prediction for each data point
</span><span class="n">proba</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_sc</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">proba</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1">#print out accuracy
</span><span class="k">print</span><span class="p">(</span><span class="s">"ACC"</span><span class="p">,</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">classes</span><span class="p">))</span>
</code></pre></div></div>

<p>This particular model achieved 92.98% accuracy, which is pretty
impressive. If we could give the model more data, hopefully it would
improve even further.</p>

<p><strong>CONCLUSION</strong></p>

<p>Now you’ve had a gentle introduction into how Feed Forward Neural
Networks learn, and how <em>you</em> can implement one in python. The material
covered here just scratches the surface of what Neural Networks can do.
Neural Networks of all types play huge roles in new technologies like
self driving cars to recognize objects like traffic signs and
pedestrians, and in medicine to reduce noise on Electrocardiograms<sup id="fnref:7"><a href="#fn:7" class="footnote">7</a></sup>.
The flexibility and application of Neural Networks far outstrips our
coverage here.</p>

<p><em>Interested in exploring how we can learn from your data to automate
your tasks? Get in touch with us!</em></p>

<p><strong>More Resources:</strong></p>

<ol>
  <li>
    <p>3Blue1Brown <a href="https://www.youtube.com/watch?v=aircAruvnKk">Neural Networks</a>,
<a href="https://www.youtube.com/watch?v=IHZwWFHWa-w">Gradient Descent</a>,
<a href="https://www.youtube.com/watch?v=Ilg3gGewQ5U">Backpropagation</a>,
<a href="https://www.youtube.com/watch?v=tIeHLnjs5U8">Backprop with Calculus</a></p>
  </li>
  <li>
    <p><a href="https://github.com/janishar/mit-deep-learning-book-pdf/blob/master/complete-book-pdf/deeplearningbook.pdf">Deep Learning Book</a></p>
  </li>
  <li>
    <p>Towards Data Science
<a href="https://towardsdatascience.com/nns-aynk-c34efe37f15a">1</a>
<a href="https://towardsdatascience.com/introduction-to-neural-networks-ead8ec1dc4dd">2</a>
<a href="https://towardsdatascience.com/deep-learning-feedforward-neural-network-26a6705dbdc7">3</a></p>
  </li>
  <li>
    <p><a href="https://data.world/health/breast-cancer-wisconsin">Wisconsin Breast Cancer
Data</a></p>
  </li>
</ol>

<p><strong>Refrences:</strong></p>

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p><a href="//www.openclinical.org/neuralnetworksinhealthcare.html">//www.openclinical.org/neuralnetworksinhealthcare.html</a> <a href="#fnref:1" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p><a href="//citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.101.2647&amp;rep=rep1&amp;type=pdf">//citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.101.2647&amp;rep=rep1&amp;type=pdf</a> <a href="#fnref:2" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:3">
      <p><a href="https://data.world/health/breast-cancer-wisconsin">https://data.world/health/breast-cancer-wisconsin</a> <a href="#fnref:3" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:4">
      <p><a href="https://pdfs.semanticscholar.org/9779/cb9faedb85515370590f89e8a1f1f922fdca.pdf">https://pdfs.semanticscholar.org/9779/cb9faedb85515370590f89e8a1f1f922fdca.pdf</a> <a href="#fnref:4" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:5">
      <p><a href="https://arxiv.org/abs/1412.6830">https://arxiv.org/abs/1412.6830</a> <a href="#fnref:5" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:6">
      <p><a href="https://data.world/health/breast-cancer-wisconsin">https://data.world/health/breast-cancer-wisconsin</a> <a href="#fnref:6" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:7">
      <p><a href="https://www.ncbi.nlm.nih.gov/pubmed/20865492">https://www.ncbi.nlm.nih.gov/pubmed/20865492</a> <a href="#fnref:7" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>

</article>





<section class="rss">
  <p class="rss-subscribe text"><strong>Subscribe <a href="http://healthstarinfo.com/goraft/feed.xml">via RSS</a></strong></p>
</section>

<!-- <section class="share_footer">
  
    
    
      <a href="//twitter.com/share?text=Neural+Networks&url=http%3A%2F%2Flocalhost%3A4000http%3A%2F%2Fhealthstarinfo.com%2Fgoraft%2F2018%2F10%2F12%2Fa-gentle-intorduction-to-feed-forward-neural-networks.html&via=TheBenCentra"
        onclick="window.open(this.href, 'twitter-share', 'width=550,height=255');return false;">
        <i class="fa fa-twitter fa-lg"></i>
      </a>
    
    
    
    
    
    
    
  
    
    
    
      <a href="//www.facebook.com/sharer.php?t=Neural+Networks&u=http%3A%2F%2Flocalhost%3A4000http%3A%2F%2Fhealthstarinfo.com%2Fgoraft%2F2018%2F10%2F12%2Fa-gentle-intorduction-to-feed-forward-neural-networks.html"
        onclick="window.open(this.href, 'facebook-share', 'width=550,height=255');return false;">
        <i class="fa fa-facebook fa-lg"></i>
      </a>
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
      <a href="//www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Flocalhost%3A4000http%3A%2F%2Fhealthstarinfo.com%2Fgoraft%2F2018%2F10%2F12%2Fa-gentle-intorduction-to-feed-forward-neural-networks.html"
        onclick="window.open(this.href, 'linkedin-share', 'width=550,height=255');return false;">
        <i class="fa fa-linkedin fa-lg"></i>
      </a>
    
    
    
    
  
    
    
    
    
      <a href="//plus.google.com/share?title=Neural+Networks&url=http%3A%2F%2Flocalhost%3A4000http%3A%2F%2Fhealthstarinfo.com%2Fgoraft%2F2018%2F10%2F12%2Fa-gentle-intorduction-to-feed-forward-neural-networks.html"
        onclick="window.open(this.href, 'google-plus-share', 'width=550,height=255');return false;">
        <i class="fa fa-google-plus fa-lg"></i>
      </a>
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
      <a href="//www.pinterest.com/pin/create/button/?description=Neural+Networks&url=http%3A%2F%2Flocalhost%3A4000http%3A%2F%2Fhealthstarinfo.com%2Fgoraft%2F2018%2F10%2F12%2Fa-gentle-intorduction-to-feed-forward-neural-networks.html&media=http://localhost:4000http://healthstarinfo.com/goraft/assets/header_image.jpg"
        onclick="window.open(this.href, 'pinterest-share', 'width=550,height=255');return false;">
        <i class="fa fa-pinterest fa-lg"></i>
      </a>
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
      <a href="//www.reddit.com/submit" onclick="window.location = '//www.reddit.com/submit?url=' + encodeURIComponent('http://localhost:4000http://healthstarinfo.com/goraft/2018/10/12/a-gentle-intorduction-to-feed-forward-neural-networks.html') + '&title=Neural Networks'; return false">
        <i class="fa fa-reddit fa-lg"></i>
      </a>
    
    
  
    
    
    
    
    
    
    
    
  
</section>
 -->





</div>
</div>

    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <div class="footer-logo site-contact">
      <img src="../assets/raft-name-logo.png" />
    </div>

    <div class="site-contact">

      <div class="address-footer">
        1801 Reston Pkwy <br />
        Suite #102 <br />
        Reston, VA 20190
      </div>

        
          
            <a href="" title="Follow me on Twitter">
              <i class="fa fa-twitter"></i>
            </a>
          
        
          
            <a href="http://" title="Friend me on Facebook">
              <i class="fa fa-facebook"></i>
            </a>
          
        
          
            <a href="https://github.com/bencentra" title="Fork me on GitHub">
              <i class="fa fa-github"></i>
            </a>
          
        
          
            <a href="https://www.linkedin.com/pub/ben-centra/47/769/60a" title="Connect with me on LinkedIn">
              <i class="fa fa-linkedin"></i>
            </a>
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        

    </div>

    <div class="site-contact">

      <div class="address-footer-double">
        <a href="tel:5715264106"><i class="fa fa-phone"></i>(571)-526-4106</a><br />
        <a href="tel:5715264106"><i class="fa fa-fax"></i>(571)-526-4106</a><br />
        <a href="mailto:info@goraft.tech?Subject=goraft.tech%20contact"><i class="fa fa-envelope"></i>info@goraft.tech</a>
      </div>

    </div>

  </div>

</footer>

<div id="copyright">&copy; Raft 2020</div>

<!-- Scripts -->
<script src="//code.jquery.com/jquery-3.4.1.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.1/js/lightbox.min.js"></script>
<script src="//unpkg.com/popper.js@1"></script>
<script src="//unpkg.com/tippy.js@5"></script>

<script type="text/javascript">
$(document).ready(function() {
  // Default syntax highlighting
  hljs.initHighlightingOnLoad();

  // Header
  var menuToggle = $('#js-mobile-menu').unbind();
  $('#js-navigation-menu').removeClass("show");
  menuToggle.on('click', function(e) {
    e.preventDefault();
    $('#js-navigation-menu').slideToggle(function(){
      if($('#js-navigation-menu').is(':hidden')) {
        $('#js-navigation-menu').removeAttr('style');
      }
    });
  });

	// Enable tooltips via Tippy.js
	if (Array.isArray(window.tooltips)) {
		window.tooltips.forEach(function(tooltip) {
			var selector = tooltip[0];
			var config = tooltip[1];
			tippy(selector, config);
		})
	}
});

</script>






  </body>

</html>
